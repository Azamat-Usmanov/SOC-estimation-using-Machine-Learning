{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM (Long-short time memory) model for SOC prediction with using LG 18650HG2 Li-ion Battery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import time\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = '../../datasets/LG_dataset/LG_HG2_processed'\n",
    "FEATURE_COLS = ['Voltage [V]', 'Current [A]', 'Temperature [degC]', 'Power [W]', 'Cumulative_Capacity_Ah']\n",
    "LABEL_COL = 'SOC [-]'\n",
    "BATCH_SIZE = 128\n",
    "SEQUENCE_LENGTH = 20  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_data(directory, temperatures):\n",
    "    frames = []    \n",
    "    for temp_folder in os.listdir(directory):\n",
    "        if temp_folder in temperatures:\n",
    "            temp_path = os.path.join(directory, temp_folder)\n",
    "            for file in os.listdir(temp_path):\n",
    "                if 'Charge' in file or 'Dis' in file:\n",
    "                    continue  # Skip constant charge and discharge files\n",
    "                if file.endswith('.csv'):\n",
    "                    df = pd.read_csv(os.path.join(temp_path, file))\n",
    "                    df['SourceFile'] = file\n",
    "\n",
    "                    # Calculate power\n",
    "                    df['Power [W]'] = df['Voltage [V]'] * df['Current [A]']\n",
    "                    \n",
    "                    frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for LSTM\n",
    "class BatteryDatasetLSTM(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor, sequence_length=50, filenames=None, times=None):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.features = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "        self.filenames = filenames \n",
    "        self.times = times \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_end = idx + self.sequence_length\n",
    "        sequence = self.features[idx:idx_end]\n",
    "        label = self.labels[idx_end - 1]\n",
    "        filename = self.filenames[idx_end - 1]\n",
    "        time = self.times[idx_end - 1]  \n",
    "\n",
    "        sequence = sequence.clone().detach()\n",
    "        label = label.clone().detach()\n",
    "\n",
    "        return sequence, label, filename, time\n",
    "    \n",
    "    def get_unique_filenames(self):\n",
    "        return set(self.filenames)\n",
    "    \n",
    "    def get_times(self):\n",
    "        return self.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoCLSTM Model\n",
    "class SoCLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SoCLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=x.dtype, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=x.dtype, device=x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with validation\n",
    "def train_and_validate(model, criterion, optimizer, train_loader, val_loader, epochs, device, patience=5, min_delta=0.0001, flag=False):\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        epoch_start_time = time.time()\n",
    "        for _, (sequences, labels, _, _) in enumerate(tqdm(train_loader, desc=f'Epoch: {epoch}/{epochs}')):  \n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            labels = labels.unsqueeze(1) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - epoch_start_time\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels, _, _ in val_loader:  \n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                labels = labels.unsqueeze(1)  \n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "        print(f'Time taken for epoch: {epoch_time:.8f} seconds')\n",
    "        \n",
    "        if flag:\n",
    "            model_path = \"soc_lstm_model.pth\"\n",
    "            torch.save({'model_state_dict': model.state_dict(), 'input_size': len(FEATURE_COLS)}, model_path)\n",
    "        if epochs_no_improve >= patience:\n",
    "            print('Early stopping triggered')\n",
    "            #break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_to_process = [folder for folder in os.listdir(PROCESSED_DATA_DIR) if 'degC' in folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Time [min]</th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Voltage [V]</th>\n",
       "      <th>Current [A]</th>\n",
       "      <th>Temperature [degC]</th>\n",
       "      <th>Capacity [Ah]</th>\n",
       "      <th>Time_diff</th>\n",
       "      <th>Cumulative_Capacity_Ah</th>\n",
       "      <th>SOC [-]</th>\n",
       "      <th>Rounded_Time</th>\n",
       "      <th>SourceFile</th>\n",
       "      <th>Power [W]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 09:53:14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.18936</td>\n",
       "      <td>-0.05108</td>\n",
       "      <td>23.34519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005569</td>\n",
       "      <td>0</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>-0.213993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 09:53:14</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.602</td>\n",
       "      <td>4.18784</td>\n",
       "      <td>-0.09450</td>\n",
       "      <td>23.34519</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>-0.395751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 09:53:15</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>1.501</td>\n",
       "      <td>4.18767</td>\n",
       "      <td>-0.09450</td>\n",
       "      <td>23.34519</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>2</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>-0.395735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 09:53:16</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>2.502</td>\n",
       "      <td>4.18750</td>\n",
       "      <td>-0.09450</td>\n",
       "      <td>23.34519</td>\n",
       "      <td>-0.00006</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>3</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>-0.395719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 09:53:17</td>\n",
       "      <td>0.059983</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.18734</td>\n",
       "      <td>-0.09195</td>\n",
       "      <td>23.34519</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>4</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>-0.385026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532257</th>\n",
       "      <td>2018-12-18 18:24:55</td>\n",
       "      <td>112.126150</td>\n",
       "      <td>6727.569</td>\n",
       "      <td>3.48709</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-9.77974</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-2.112200</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6728</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532258</th>\n",
       "      <td>2018-12-18 18:24:56</td>\n",
       "      <td>112.142883</td>\n",
       "      <td>6728.573</td>\n",
       "      <td>3.48726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-9.77974</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-2.112200</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6729</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532259</th>\n",
       "      <td>2018-12-18 18:24:57</td>\n",
       "      <td>112.159483</td>\n",
       "      <td>6729.569</td>\n",
       "      <td>3.48726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-9.77974</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-2.112200</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6730</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532260</th>\n",
       "      <td>2018-12-18 18:24:58</td>\n",
       "      <td>112.176183</td>\n",
       "      <td>6730.571</td>\n",
       "      <td>3.48726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-9.77974</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-2.112200</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6731</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532261</th>\n",
       "      <td>2018-12-18 18:24:59</td>\n",
       "      <td>112.192867</td>\n",
       "      <td>6731.572</td>\n",
       "      <td>3.48726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-9.77974</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-2.112200</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6732</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532262 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  Time [min]  Time [s]  Voltage [V]  Current [A]  \\\n",
       "0       2018-11-08 09:53:14    0.000000     0.000      4.18936     -0.05108   \n",
       "1       2018-11-08 09:53:14    0.010033     0.602      4.18784     -0.09450   \n",
       "2       2018-11-08 09:53:15    0.025017     1.501      4.18767     -0.09450   \n",
       "3       2018-11-08 09:53:16    0.041700     2.502      4.18750     -0.09450   \n",
       "4       2018-11-08 09:53:17    0.059983     3.599      4.18734     -0.09195   \n",
       "...                     ...         ...       ...          ...          ...   \n",
       "532257  2018-12-18 18:24:55  112.126150  6727.569      3.48709      0.00000   \n",
       "532258  2018-12-18 18:24:56  112.142883  6728.573      3.48726      0.00000   \n",
       "532259  2018-12-18 18:24:57  112.159483  6729.569      3.48726      0.00000   \n",
       "532260  2018-12-18 18:24:58  112.176183  6730.571      3.48726      0.00000   \n",
       "532261  2018-12-18 18:24:59  112.192867  6731.572      3.48726      0.00000   \n",
       "\n",
       "        Temperature [degC]  Capacity [Ah]  Time_diff  Cumulative_Capacity_Ah  \\\n",
       "0                 23.34519        0.00000   0.000000                0.000000   \n",
       "1                 23.34519       -0.00001   0.000029               -0.000015   \n",
       "2                 23.34519       -0.00004   0.000028               -0.000039   \n",
       "3                 23.34519       -0.00006   0.000028               -0.000065   \n",
       "4                 23.34519       -0.00009   0.000028               -0.000093   \n",
       "...                    ...            ...        ...                     ...   \n",
       "532257            -9.77974       -2.10860   0.000027               -2.112200   \n",
       "532258            -9.77974       -2.10860   0.000028               -2.112200   \n",
       "532259            -9.77974       -2.10860   0.000027               -2.112200   \n",
       "532260            -9.77974       -2.10860   0.000029               -2.112200   \n",
       "532261            -9.77974       -2.10860   0.000029               -2.112200   \n",
       "\n",
       "         SOC [-]  Rounded_Time                SourceFile  Power [W]  \n",
       "0       1.005569             0  562_Mixed6_processed.csv  -0.213993  \n",
       "1       0.999995             1  562_Mixed6_processed.csv  -0.395751  \n",
       "2       0.999987             2  562_Mixed6_processed.csv  -0.395735  \n",
       "3       0.999977             3  562_Mixed6_processed.csv  -0.395719  \n",
       "4       0.999966             4  562_Mixed6_processed.csv  -0.385026  \n",
       "...          ...           ...                       ...        ...  \n",
       "532257  0.170802          6728  604_Mixed8_processed.csv   0.000000  \n",
       "532258  0.170802          6729  604_Mixed8_processed.csv   0.000000  \n",
       "532259  0.170802          6730  604_Mixed8_processed.csv   0.000000  \n",
       "532260  0.170802          6731  604_Mixed8_processed.csv   0.000000  \n",
       "532261  0.170802          6732  604_Mixed8_processed.csv   0.000000  \n",
       "\n",
       "[532262 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(PROCESSED_DATA_DIR, temperatures_to_process)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Time [min]</th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Voltage [V]</th>\n",
       "      <th>Current [A]</th>\n",
       "      <th>Temperature [degC]</th>\n",
       "      <th>Capacity [Ah]</th>\n",
       "      <th>Time_diff</th>\n",
       "      <th>Cumulative_Capacity_Ah</th>\n",
       "      <th>SOC [-]</th>\n",
       "      <th>Rounded_Time</th>\n",
       "      <th>SourceFile</th>\n",
       "      <th>Power [W]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 09:53:14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.693907</td>\n",
       "      <td>0.421254</td>\n",
       "      <td>0.821057</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.531129</td>\n",
       "      <td>1.005569</td>\n",
       "      <td>0</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>0.410519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 09:53:14</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.602</td>\n",
       "      <td>1.688779</td>\n",
       "      <td>0.402139</td>\n",
       "      <td>0.821057</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.531109</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>0.387702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 09:53:15</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>1.501</td>\n",
       "      <td>1.688205</td>\n",
       "      <td>0.402139</td>\n",
       "      <td>0.821057</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.531078</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>2</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>0.387704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 09:53:16</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>2.502</td>\n",
       "      <td>1.687632</td>\n",
       "      <td>0.402139</td>\n",
       "      <td>0.821057</td>\n",
       "      <td>-0.00006</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.531044</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>3</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>0.387707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 09:53:17</td>\n",
       "      <td>0.059983</td>\n",
       "      <td>3.599</td>\n",
       "      <td>1.687092</td>\n",
       "      <td>0.403262</td>\n",
       "      <td>0.821057</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.531006</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>4</td>\n",
       "      <td>562_Mixed6_processed.csv</td>\n",
       "      <td>0.389049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532257</th>\n",
       "      <td>2018-12-18 18:24:55</td>\n",
       "      <td>112.126150</td>\n",
       "      <td>6727.569</td>\n",
       "      <td>-0.675525</td>\n",
       "      <td>0.443741</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-1.259410</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6728</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.437382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532258</th>\n",
       "      <td>2018-12-18 18:24:56</td>\n",
       "      <td>112.142883</td>\n",
       "      <td>6728.573</td>\n",
       "      <td>-0.674951</td>\n",
       "      <td>0.443741</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-1.259410</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6729</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.437382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532259</th>\n",
       "      <td>2018-12-18 18:24:57</td>\n",
       "      <td>112.159483</td>\n",
       "      <td>6729.569</td>\n",
       "      <td>-0.674951</td>\n",
       "      <td>0.443741</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-1.259410</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6730</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.437382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532260</th>\n",
       "      <td>2018-12-18 18:24:58</td>\n",
       "      <td>112.176183</td>\n",
       "      <td>6730.571</td>\n",
       "      <td>-0.674951</td>\n",
       "      <td>0.443741</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-1.259410</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6731</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.437382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532261</th>\n",
       "      <td>2018-12-18 18:24:59</td>\n",
       "      <td>112.192867</td>\n",
       "      <td>6731.572</td>\n",
       "      <td>-0.674951</td>\n",
       "      <td>0.443741</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-2.10860</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-1.259410</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>6732</td>\n",
       "      <td>604_Mixed8_processed.csv</td>\n",
       "      <td>0.437382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532262 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  Time [min]  Time [s]  Voltage [V]  Current [A]  \\\n",
       "0       2018-11-08 09:53:14    0.000000     0.000     1.693907     0.421254   \n",
       "1       2018-11-08 09:53:14    0.010033     0.602     1.688779     0.402139   \n",
       "2       2018-11-08 09:53:15    0.025017     1.501     1.688205     0.402139   \n",
       "3       2018-11-08 09:53:16    0.041700     2.502     1.687632     0.402139   \n",
       "4       2018-11-08 09:53:17    0.059983     3.599     1.687092     0.403262   \n",
       "...                     ...         ...       ...          ...          ...   \n",
       "532257  2018-12-18 18:24:55  112.126150  6727.569    -0.675525     0.443741   \n",
       "532258  2018-12-18 18:24:56  112.142883  6728.573    -0.674951     0.443741   \n",
       "532259  2018-12-18 18:24:57  112.159483  6729.569    -0.674951     0.443741   \n",
       "532260  2018-12-18 18:24:58  112.176183  6730.571    -0.674951     0.443741   \n",
       "532261  2018-12-18 18:24:59  112.192867  6731.572    -0.674951     0.443741   \n",
       "\n",
       "        Temperature [degC]  Capacity [Ah]  Time_diff  Cumulative_Capacity_Ah  \\\n",
       "0                 0.821057        0.00000   0.000000                1.531129   \n",
       "1                 0.821057       -0.00001   0.000029                1.531109   \n",
       "2                 0.821057       -0.00004   0.000028                1.531078   \n",
       "3                 0.821057       -0.00006   0.000028                1.531044   \n",
       "4                 0.821057       -0.00009   0.000028                1.531006   \n",
       "...                    ...            ...        ...                     ...   \n",
       "532257           -0.992532       -2.10860   0.000027               -1.259410   \n",
       "532258           -0.992532       -2.10860   0.000028               -1.259410   \n",
       "532259           -0.992532       -2.10860   0.000027               -1.259410   \n",
       "532260           -0.992532       -2.10860   0.000029               -1.259410   \n",
       "532261           -0.992532       -2.10860   0.000029               -1.259410   \n",
       "\n",
       "         SOC [-]  Rounded_Time                SourceFile  Power [W]  \n",
       "0       1.005569             0  562_Mixed6_processed.csv   0.410519  \n",
       "1       0.999995             1  562_Mixed6_processed.csv   0.387702  \n",
       "2       0.999987             2  562_Mixed6_processed.csv   0.387704  \n",
       "3       0.999977             3  562_Mixed6_processed.csv   0.387707  \n",
       "4       0.999966             4  562_Mixed6_processed.csv   0.389049  \n",
       "...          ...           ...                       ...        ...  \n",
       "532257  0.170802          6728  604_Mixed8_processed.csv   0.437382  \n",
       "532258  0.170802          6729  604_Mixed8_processed.csv   0.437382  \n",
       "532259  0.170802          6730  604_Mixed8_processed.csv   0.437382  \n",
       "532260  0.170802          6731  604_Mixed8_processed.csv   0.437382  \n",
       "532261  0.170802          6732  604_Mixed8_processed.csv   0.437382  \n",
       "\n",
       "[532262 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data[FEATURE_COLS] = scaler.fit_transform(data[FEATURE_COLS])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_files = np.array(list(set(data['SourceFile'])))\n",
    "train_files, temp_files = train_test_split(unique_files, test_size=0.2, random_state=52)\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_filenames(df, filenames):\n",
    "    return df[df['SourceFile'].isin(filenames)]\n",
    "\n",
    "# Filter data for each set\n",
    "train_data = filter_data_by_filenames(data, train_files)\n",
    "val_data = filter_data_by_filenames(data, val_files)\n",
    "test_data = filter_data_by_filenames(data, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "train_tensor = torch.tensor(train_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "train_labels = torch.tensor(train_data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "val_tensor = torch.tensor(val_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "val_labels = torch.tensor(val_data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "test_tensor = torch.tensor(test_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "test_labels = torch.tensor(test_data[LABEL_COL].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert filtered data to tensors and create dataset instances\n",
    "train_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(train_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(train_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    train_data['SourceFile'].values,\n",
    "    train_data['Time [s]'].values  \n",
    ")\n",
    "\n",
    "val_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(val_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(val_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    val_data['SourceFile'].values,\n",
    "    val_data['Time [s]'].values  \n",
    ")\n",
    "\n",
    "test_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(test_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(test_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    test_data['SourceFile'].values,\n",
    "    test_data['Time [s]'].values  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: {'610_HWFET_processed.csv', '562_Mixed4_processed.csv', '610_UDDS_processed.csv', '575_HPPC_processed.csv', '576_UDDS_processed.csv', '567_Mixed2_processed.csv', '602_Mixed4_processed.csv', '590_PausCycl_processed.csv', '552_Mixed4_processed.csv', '596_HWFET_processed.csv', '589_UDDS_processed.csv', '610_US06_processed.csv', '557_Cap_1C_processed.csv', '610_Cap_1C_processed.csv', '562_Mixed6_processed.csv', '557_Mixed3_processed.csv', '589_Mixed2_processed.csv', '611_Cap_1C_processed.csv', '551_LA92_processed.csv', '571_Mixed6_processed.csv', '562_Mixed5_processed.csv', '601_US06_processed.csv', '555_HPPC_processed.csv', '551_Mixed2_processed.csv', '556_HWFET_processed.csv', '602_Cap_1C_processed.csv', '604_PausCycl_processed.csv', '604_Mixed8_processed.csv', '611_Mixed8_processed.csv', '556_Mixed2_processed.csv', '551_UDDS_processed.csv', '604_Mixed6_processed.csv', '589_Mixed1_processed.csv', '556_Mixed1_processed.csv', '571_Mixed7_processed.csv', '556_UDDS_processed.csv', '552_PausCycl_processed.csv', '552_Mixed3_processed.csv', '571_Mixed8_processed.csv', '571_Mixed5_processed.csv', '604_Mixed7_processed.csv', '593_HPPC_processed.csv', '590_Mixed7_processed.csv', '601_Mixed2_processed.csv', '552_Cap_1C_processed.csv', '589_US06_processed.csv', '556_US06_processed.csv', '590_Mixed8_processed.csv', '590_Mixed4_processed.csv', '562_PausCycl_processed.csv', '590_Mixed5_processed.csv', '567_US06_processed.csv', '551_Mixed1_processed.csv', '607_HPPC_processed.csv', '596_LA92_processed.csv', '611_Mixed3_processed.csv', '601_Mixed1_processed.csv', '611_Mixed6_processed.csv', '562_Mixed7_processed.csv', '576_HWFET_processed.csv', '562_Mixed8_processed.csv', '610_LA92_processed.csv', '571_Mixed4_processed.csv', '571_Cap_1C_processed.csv', '552_Mixed5_processed.csv', '571_PausCycl_processed.csv', '611_Mixed7_processed.csv', '596_Cap_1C_processed.csv', '611_Mixed4_processed.csv', '552_Mixed6_processed.csv', '596_UDDS_processed.csv', '589_HWFET_processed.csv'}\n",
      "\n",
      "Validation files: {'585_HPPC_processed.csv', '551_US06_processed.csv', '576_Cap_1C_processed.csv', '551_Cap_1C_processed.csv', '611_Mixed5_processed.csv', '604_Mixed3_processed.csv', '549_HPPC_processed.csv', '556_LA92_processed.csv', '552_Mixed7_processed.csv'}\n",
      "\n",
      "Testing files: {'567_Mixed1_processed.csv', '611_PausCycl_processed.csv', '589_Cap_1C_processed.csv', '602_Mixed5_processed.csv', '552_Mixed8_processed.csv', '590_Mixed6_processed.csv', '610_Mixed1_processed.csv', '589_LA92_processed.csv', '610_Mixed2_processed.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Print file names used in training, validation, and testing\n",
    "train_files = train_dataset.get_unique_filenames()\n",
    "val_files = val_dataset.get_unique_filenames()\n",
    "test_files = test_dataset.get_unique_filenames()\n",
    "\n",
    "train_files_sorted = sorted(train_files)\n",
    "val_files_sorted = sorted(val_files)\n",
    "test_files_sorted = sorted(test_files)\n",
    "\n",
    "print(\"Training files:\", train_files)\n",
    "print(\"\\nValidation files:\", val_files)\n",
    "print(\"\\nTesting files:\", test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: torch.Size([428005, 5])\n",
      "Test features shape: torch.Size([47112, 5])\n",
      "Train labels shape: torch.Size([428005])\n",
      "Test labels shape: torch.Size([47112])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape:\", train_tensor.shape)\n",
    "print(\"Test features shape:\", test_tensor .shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna objective function\n",
    "EPOCHS = 10\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_size = trial.suggest_int('hidden_size', 16, 128)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "\n",
    "    # Instantiate model with suggested hyperparameters\n",
    "    model = SoCLSTM(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers).type(torch.float32).to(device)\n",
    "\n",
    "    # Define your loss function and optimizer with suggested hyperparameters\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Call your train and validate function\n",
    "    history = train_and_validate(model, criterion, optimizer, train_loader, val_loader, EPOCHS, device)\n",
    "\n",
    "    # Extract last validation loss\n",
    "    last_val_loss = history['val_loss'][-1]\n",
    "    return last_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Extract best trial\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial}\")\n",
    "\n",
    "best_hyperparams = study.best_trial.params\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "\n",
    "# Plot optimization history\n",
    "optimization_history = plot_optimization_history(study)\n",
    "optimization_history.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "hidden_size = best_hyperparams['hidden_size']\n",
    "num_layers = best_hyperparams['num_layers']\n",
    "lr = best_hyperparams['learning_rate']\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "model = SoCLSTM(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers)\n",
    "model.to(device).type(torch.float32)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate the model\n",
    "history = train_and_validate(model, criterion, optimizer, train_loader, val_loader, EPOCHS, device, flag=True)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model_path = \"soc_lstm_model.pth\"\n",
    "torch.save({'model_state_dict': model.state_dict(), 'input_size': len(FEATURE_COLS)}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"soc_lstm_model.pth\"\n",
    "    \n",
    "def load_lstm_model(model_path, input_size, hidden_size, num_layers):\n",
    "    model = SoCLSTM(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers).to(device).type(torch.float32)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device)['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "loaded_model = load_lstm_model(model_path, input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _, _ in test_loader: \n",
    "            outputs = model(inputs)\n",
    "            test_predictions.extend(outputs.cpu().view(-1).tolist())\n",
    "            test_labels.extend(labels.cpu().view(-1).tolist())\n",
    "\n",
    "    return test_predictions, test_labels\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions, test_labels = test_model(loaded_model, test_loader, device)\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for error calculation\n",
    "test_predictions_np = np.array(test_predictions)\n",
    "test_labels_np = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics MAE, MSE, STD\n",
    "mse = mean_squared_error(test_labels_np, test_predictions_np)\n",
    "mae = mean_absolute_error(test_labels_np, test_predictions_np)\n",
    "stddev = np.std(test_labels_np - test_predictions_np)\n",
    "\n",
    "print(f\"Test MSE: {mse:.6f}\")\n",
    "print(f\"Test MAE: {mae:.6f}\")\n",
    "print(f\"Test StdDev: {stddev:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(test_labels, test_predictions, alpha=0.5)\n",
    "plt.xlabel('True Values [SOC]')\n",
    "plt.ylabel('Predictions [SOC]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.plot([0, 1], [0, 1], color='red') \n",
    "plt.title('Predicted SOC vs True SOC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_results = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, filenames, times in test_loader: \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions = outputs.cpu().view(-1).numpy()\n",
    "            labels = labels.cpu().view(-1).numpy()\n",
    "\n",
    "            for filename, time, pred, label in zip(filenames, times, predictions, labels):\n",
    "                if filename not in test_results:\n",
    "                    test_results[filename] = {'times': [], 'predictions': [], 'labels': []}\n",
    "                test_results[filename]['times'].append(time)\n",
    "                test_results[filename]['predictions'].append(pred)\n",
    "                test_results[filename]['labels'].append(label)\n",
    "\n",
    "    return test_results\n",
    "\n",
    "def plot_soc_over_time(test_results):\n",
    "    for filename, data in test_results.items():\n",
    "        times = data['times']\n",
    "        predictions = data['predictions']\n",
    "        labels = data['labels']\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(times, labels, label='True SOC', color='blue')\n",
    "        plt.plot(times, predictions, label='Predicted SOC', color='red')\n",
    "        plt.title(f'Test File: {filename}')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('SOC')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = test_model(loaded_model, test_loader, device)\n",
    "\n",
    "# Plot the SOC over time for each test file\n",
    "plot_soc_over_time(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
